{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_split(res, seps):\n",
    "    for sep in seps:\n",
    "        s, res = res, []\n",
    "        for seq in s:\n",
    "            res += seq.split(sep)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = []\n",
    "\n",
    "total_words = 0\n",
    "total_twits = 0\n",
    "count_words = {}\n",
    "freq_in_twits = {}\n",
    "twits_length = {}\n",
    "\n",
    "separators = ['.', ',', '*', '\"', \"'\", ':', ';', '!', '?', '@']\n",
    "ignore_word_type = ['PREP', 'CONJ', 'PRCL', 'INTJ', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence(line):\n",
    "    sentence = []\n",
    "    ignore_flag = False\n",
    "    for word in line:\n",
    "        if ignore_flag:\n",
    "            ignore_flag = False\n",
    "            continue\n",
    "        if word == '#':\n",
    "            ignore_flag = True\n",
    "            continue\n",
    "        if r\".com/\" not in word:\n",
    "            word = my_split([word], separators)\n",
    "            sentence += word\n",
    "        # print(word, morph.normal_forms(word)[0], morph.tag(word)[0].POS)\n",
    "    sentence = [morph.normal_forms(word)[0] for word in sentence\n",
    "                if word != '' and morph.tag(word)[0].POS not in ignore_word_type]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceNote:\n",
    "    def __init__(self, line):\n",
    "        line = line.split()\n",
    "        day = list(map(int, line[0].split('-')))\n",
    "        time = list(map(int, line[1].split(':')))\n",
    "        self.time = datetime(day = day[2], month = day[1], year = day[0], hour = time[0], minute = time[1])\n",
    "        raw_sentence = parse_sentence(line[2:])\n",
    "        self.size = len(raw_sentence)\n",
    "        self.used_words = {}\n",
    "        for word in raw_sentence:\n",
    "            if self.used_words.get(word, 0) == 0:\n",
    "                self.used_words[word] = 0\n",
    "            self.used_words[word] += 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"    \".join([str(self.time), str(self.used_words.items())])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"data_utf8.txt\", encoding='UTF8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        sentence = SentenceNote(line)\n",
    "        sentence_list.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_twits = len(sentence_list)\n",
    "\n",
    "for sentence in sentence_list:\n",
    "    total_words += sentence.size\n",
    "    if twits_length.get(sentence.size, 0) == 0:\n",
    "        twits_length[sentence.size] = 0\n",
    "    twits_length[sentence.size] += 1\n",
    "    \n",
    "    for word, count in sentence.used_words.items():\n",
    "        if count_words.get(word, 0) == 0:\n",
    "            count_words[word] = 0\n",
    "        count_words[word] += count\n",
    "        if freq_in_twits.get(word, 0) == 0:\n",
    "            freq_in_twits[word] = 0\n",
    "        freq_in_twits[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"frequency.txt\", 'w', encoding='UTF8')\n",
    "for word, cnt in sorted(freq_in_twits.items(), key= lambda x: x[1], reverse = True):\n",
    "    print(\"%s - %d - %.3f%%\" % (word, freq_in_twits[word], freq_in_twits[word]/total_twits*100), file=file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"twits_length.txt\", 'w', encoding='UTF8')\n",
    "sum = 0\n",
    "for length, cnt in sorted(twits_length.items(), key= lambda x: x[1], reverse = True):\n",
    "    sum += cnt\n",
    "    print(\"%d - %d - %.3f%%\" % (length, cnt, cnt/total_twits*100), file= file)\n",
    "file.close()\n",
    "sum == total_twits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"word_score.txt\", 'w', encoding='UTF8')\n",
    "for word, cnt in sorted(freq_in_twits.items(), key= lambda x: x[1], reverse = True):\n",
    "    print(word, \"\" if freq_in_twits[word] > 1 else 0, file=file)\n",
    "file.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
